{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2048ace1-d64b-48cf-a434-eaaaeaf87e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 Output:\n",
      " [[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n",
      "Layer 2 Output:\n",
      " [[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n",
      "Layer 3 Output:\n",
      " [[-3.25518    5.287376 ]\n",
      " [-7.50489   10.157067 ]\n",
      " [-0.813253   0.2587991]]\n",
      "Layer 4 Output:\n",
      " [[-4.7064548 ]\n",
      " [-9.8771206 ]\n",
      " [ 0.04898482]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inputs, weights, and biases for previous layers\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "          [2., 5., -1., 2],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1],  # first weight matrix : 3X4 \n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5]    # 1st bias matrix : (3X1) \n",
    "\n",
    "weights2 = [[0.1, -0.14, 0.5],  # second weight matrix : 3X3 \n",
    "            [-0.5, 0.12, -0.33],\n",
    "            [-0.44, 0.73, -0.13]]\n",
    "\n",
    "biases2 = [-1, 2, -0.5]  # 2nd bias matrix : (3X1)\n",
    "weights3 = [[0.2, 0.8],  # weights matrix: 3x2\n",
    "            [0.5, -0.91],\n",
    "            [0.9, -0.95]]\n",
    "biases3 = [-1, 2]\n",
    "\n",
    "# Adding Layer 4\n",
    "weights4 = [[0.3],  # weights matrix: 2x1 (2 neurons from Layer 3 to 1 neuron in Layer 4)\n",
    "            [-0.8]]\n",
    "biases4 = [0.5]  # Single bias value for Layer 4\n",
    "\n",
    "# Convert everything into numpy arrays\n",
    "inputs_array = np.array(inputs)\n",
    "weights_array = np.array(weights)\n",
    "biases_array = np.array(biases)\n",
    "weights2_array = np.array(weights2)\n",
    "biases2_array = np.array(biases2)\n",
    "weights3_array = np.array(weights3)\n",
    "biases3_array = np.array(biases3)\n",
    "weights4_array = np.array(weights4)\n",
    "biases4_array = np.array(biases4)\n",
    "\n",
    "# Calculate the output of the first layer\n",
    "layer1_outputs = np.dot(inputs_array, weights_array.T) + biases_array\n",
    "print(\"Layer 1 Output:\\n\", layer1_outputs)\n",
    "\n",
    "# Calculate the output of the second layer\n",
    "layer2_outputs = np.dot(layer1_outputs, weights2_array.T) + biases2_array\n",
    "print(\"Layer 2 Output:\\n\", layer2_outputs)\n",
    "\n",
    "# Calculate the output of the third layer\n",
    "layer3_outputs = np.dot(layer2_outputs, weights3_array) + biases3_array\n",
    "print(\"Layer 3 Output:\\n\", layer3_outputs)\n",
    "\n",
    "# Calculate the output of the fourth layer\n",
    "layer4_outputs = np.dot(layer3_outputs, weights4_array) + biases4_array\n",
    "print(\"Layer 4 Output:\\n\", layer4_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "663a7881-da94-4279-b757-2e44d436529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17c65a98-68c9-4af0-89ee-1ca6c722924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d932d6c7-c5c4-4a62-90df-876059cfa526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Output (A1): [[0.70943349 0.5044098  0.42246732]\n",
      " [0.63255308 0.789319   0.62920257]\n",
      " [0.15182268 0.17266721 0.13853899]\n",
      " [0.54029834 0.19036055 0.17763558]\n",
      " [0.64903534 0.68196116 0.55046799]]\n",
      "Output Layer Prediction (A2): [[0.6752584  0.6752584  0.6752584 ]\n",
      " [0.7500077  0.7500077  0.7500077 ]\n",
      " [0.56012183 0.56012183 0.56012183]\n",
      " [0.57518737 0.57518737 0.57518737]\n",
      " [0.72297991 0.72297991 0.72297991]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a simple dataset\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 2)  # 100 points with 2 features (x1, x2)\n",
    "y = (X[:, 0] + X[:, 1] > 1).astype(int)  # Label is 1 if x1 + x2 > 1, else 0\n",
    "\n",
    "# Create a DataFrame for easy visualization\n",
    "data = pd.DataFrame(X, columns=[\"x1\", \"x2\"])\n",
    "data[\"y\"] = y\n",
    "data\n",
    "\n",
    "input_layer = 2\n",
    "hidden_layer = 3\n",
    "output_layer = 1\n",
    "\n",
    "np.random.seed(42)\n",
    "w1 = np.random.rand(input_layer,hidden_layer)#weights for the input to hidden\n",
    "b1 = np.zeros((1,hidden_layer))# bias for the hidden layer \n",
    "\n",
    "w2 = np.random.rand(hidden_layer,output_layer)#weight for the hidden to output\n",
    "b2 = np.zeros((1,output_layer))\n",
    "\n",
    "def forword(x):\n",
    "    z1 = np.dot(X,w1)+b1\n",
    "    a1 = relu(z1)\n",
    "\n",
    "\n",
    "    z2 = np.dot(a1,w2)+b1\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    return  a1,a2\n",
    "a1,a2 = forword(X)\n",
    "print(\"Hidden Layer Output (A1):\", a1[:5])\n",
    "print(\"Output Layer Prediction (A2):\", a2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de47ccd3-f0d6-4ddf-8003-981bc095ca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IQ Level</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>7.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>9.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>78</td>\n",
       "      <td>6.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>104</td>\n",
       "      <td>9.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>103</td>\n",
       "      <td>6.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>100</td>\n",
       "      <td>9.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>96</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    IQ Level  CGPA  Placed\n",
       "0        107  7.09       0\n",
       "1         97  6.11       0\n",
       "2        109  5.60       0\n",
       "3        122  6.69       0\n",
       "4         96  9.71       0\n",
       "..       ...   ...     ...\n",
       "95        78  6.22       0\n",
       "96       104  9.87       0\n",
       "97       103  6.97       0\n",
       "98       100  9.46       0\n",
       "99        96  8.16       0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random IQ levels (1D array: 100 samples)\n",
    "iq_levels = np.random.normal(100, 15, 100).astype(int)  # Mean=100, Std=15\n",
    "\n",
    "# Generate random CGPA values (1D array: 100 samples)\n",
    "cgpa = np.round(np.random.uniform(5.0, 10.0, 100), 2)\n",
    "\n",
    "# Define placement labels based on IQ and CGPA\n",
    "# Students with IQ > 110 and CGPA > 8.0 are more likely to get placed\n",
    "placed = np.array([1 if iq > 110 and gpa > 8.0 else 0 for iq, gpa in zip(iq_levels, cgpa)])\n",
    "\n",
    "# Combine into a pandas DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"IQ Level\": iq_levels,\n",
    "    \"CGPA\": cgpa,\n",
    "    \"Placed\": placed\n",
    "})\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974d3dbc-94a2-4c8a-8523-a3fc37377549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Relu:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class Activation_Tanh:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.tanh(inputs)\n",
    "\n",
    "class Activation_softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "\n",
    "class Actiavation_sigmoid:\n",
    "    def forward(self, inputs):\n",
    "        self.output = 1 / (1 + np.exp(-inputs))\n",
    "\n",
    "class Dense_layer:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48f6fb46-a0b9-4ad9-b1af-fdb65adb29d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation 1 output: [[0.85971189 1.55863497 0.        ]\n",
      " [0.77259509 1.41916375 0.        ]\n",
      " [0.8411723  1.61944141 0.        ]\n",
      " [0.95049936 1.80434584 0.        ]\n",
      " [0.84276299 1.33302842 0.        ]]\n",
      "Activation 2 output: [[-0.00412819  0.01565664  0.00021115 -0.01258852  0.00978278]\n",
      " [-0.00381872  0.01422721  0.00025569 -0.01144096  0.00895765]\n",
      " [-0.00459562  0.01612104  0.00054368 -0.0129712   0.01042113]\n",
      " [-0.00504218  0.01799864  0.00052304 -0.01447967  0.01154541]\n",
      " [-0.00289827  0.01369268 -0.00048876 -0.01099022  0.00783693]]\n",
      "Activation 3 output: [[0.49993839 0.50006161]\n",
      " [0.49994406 0.50005594]\n",
      " [0.4999368  0.5000632 ]\n",
      " [0.49992938 0.50007062]\n",
      " [0.49994561 0.50005439]]\n",
      "Activation 4 output: [[0.50204864]\n",
      " [0.50204864]\n",
      " [0.50204864]\n",
      " [0.50204864]\n",
      " [0.50204864]]\n",
      "Rounded Output: [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "X = data[[\"IQ Level\", \"CGPA\"]].values  # Use the raw data (without normalization)\n",
    "y = data[\"Placed\"].values.reshape(-1, 1)  # Target (reshaped for binary classification)\n",
    "\n",
    "\n",
    "# Layer 1\n",
    "dense1 = Dense_layer(2, 3)\n",
    "activation1 = Activation_Relu()\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "print(\"Activation 1 output:\", activation1.output[:5])\n",
    "\n",
    "# Layer 2\n",
    "dense2 = Dense_layer(3, 5)\n",
    "activation2 = Activation_Tanh()\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "print(\"Activation 2 output:\", activation2.output[:5])\n",
    "\n",
    "# Layer 3\n",
    "dense3 = Dense_layer(5, 2)\n",
    "activation3 = Activation_softmax()\n",
    "dense3.forward(activation2.output)\n",
    "activation3.forward(dense3.output)\n",
    "print(\"Activation 3 output:\", activation3.output[:5])\n",
    "\n",
    "# Layer 4 (Final Layer)\n",
    "dense4 = Dense_layer(2, 1)\n",
    "activation4 = Actiavation_sigmoid()\n",
    "dense4.forward(activation3.output)\n",
    "activation4.forward(dense4.output)\n",
    "print(\"Activation 4 output:\", activation4.output[:5])\n",
    "rounded_output = np.round(activation4.output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d1db2-8395-480f-85b7-066f1ea69870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
